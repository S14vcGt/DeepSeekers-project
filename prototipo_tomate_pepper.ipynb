{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pyautogui\n",
    "from PIL import Image\n",
    "\n",
    "carpeta = \"../plantvillage_dataset/grayscale/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tomate_pimienta grey\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1. Configurar rutas y parámetros\n",
    "dataset_path = carpeta  # Cambia esto a la ruta de tu dataset\n",
    "target_size = (128, 128)  # Redimensionar a 128x128\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# 2. Preprocesamiento y aumento de datos\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,  # Normalización de píxeles\n",
    "    rotation_range=20,  # Rotación aleatoria\n",
    "    width_shift_range=0.2,  # Desplazamiento horizontal aleatorio\n",
    "    height_shift_range=0.2,  # Desplazamiento vertical aleatorio\n",
    "    horizontal_flip=True,  # Volteo horizontal aleatorio\n",
    "    validation_split=0.2  # 20% de los datos para validación\n",
    ")\n",
    "\n",
    "# 3. Cargar las imágenes de las 3 clases\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=target_size,\n",
    "    color_mode='grayscale',  # Cargar en escala de grises\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Clasificación multiclase\n",
    "    classes=['Tomato___healthy', 'Tomato___Leaf_Mold', 'Pepper,_bell___healthy', 'Pepper,_bell___Bacterial_spot'],  # Tres clases\n",
    "    subset='training'  # Conjunto de entrenamiento\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=target_size,\n",
    "    color_mode='grayscale',  # Cargar en escala de grises\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Clasificación multiclase\n",
    "    classes=['Tomato___healthy', 'Tomato___Leaf_Mold', 'Pepper,_bell___healthy', 'Pepper,_bell___Bacterial_spot'],  # Tres clases\n",
    "    subset='validation'  # Conjunto de validación\n",
    ")\n",
    "\n",
    "# 4. Construir el modelo\n",
    "model = Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')  # Capa de salida para 3 clases\n",
    "])\n",
    "\n",
    "# 5. Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Pérdida para clasificación multiclase\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 6. Resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "# 7. Entrenar el modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# 8. Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Pérdida en validación: {loss}\")\n",
    "print(f\"Precisión en validación: {accuracy}\")\n",
    "\n",
    "# 9. Guardar el modelo\n",
    "model.save(\"modelo_tomate_pepper.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pyautogui\n",
    "from PIL import Image\n",
    "\n",
    "# 1. Cargar el modelo entrenado\n",
    "model = tf.keras.models.load_model(\"modelo_tomate_pepper.keras\")  # Asegúrate de que el modelo esté en la ruta correcta\n",
    "\n",
    "# 2. Definir el tamaño de la región de la pantalla a capturar\n",
    "screen_width, screen_height = 260, 260  # Resolución de 400x400\n",
    "\n",
    "# 3. Definir las etiquetas de las clases\n",
    "class_names = ['Tomate_Bueno', 'Tomate_malo', 'Pimienta_buena', 'Pimienta_mala']\n",
    "\n",
    "# 4. Función para preprocesar la imagen\n",
    "def preprocess_image(image):\n",
    "    # Convertir a escala de grises\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Redimensionar a 256x256 (tamaño esperado por el modelo)\n",
    "    resized_image = cv2.resize(gray_image, (128, 128))\n",
    "    # Normalizar los valores de píxeles\n",
    "    normalized_image = resized_image / 255.0\n",
    "    # Expandir dimensiones para que coincida con la entrada del modelo (256, 256, 1)\n",
    "    input_image = np.expand_dims(normalized_image, axis=-1)\n",
    "    input_image = np.expand_dims(input_image, axis=0)  # Añadir dimensión del batch\n",
    "    return input_image\n",
    "\n",
    "# 5. Función para predecir la clase y la confianza\n",
    "def predict_plant(image):\n",
    "    # Preprocesar la imagen\n",
    "    input_image = preprocess_image(image)\n",
    "    # Realizar la predicción\n",
    "    predictions = model.predict(input_image)\n",
    "    # Obtener la clase predicha y su confianza\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]  # Índice de la clase predicha\n",
    "    predicted_class_name = class_names[predicted_class_index]  # Nombre de la clase predicha\n",
    "    confidence = np.max(predictions)  # Confianza de la predicción (valor máximo del array de predicciones)\n",
    "    return predicted_class_name, confidence\n",
    "\n",
    "# 6. Capturar la pantalla en tiempo real y realizar predicciones\n",
    "print(\"Iniciando detección en tiempo real...\")\n",
    "while True:\n",
    "    # Capturar la pantalla\n",
    "    screenshot = pyautogui.screenshot(region=(290, 370, screen_width, screen_height))\n",
    "    screenshot = np.array(screenshot)  # Convertir a un array de NumPy\n",
    "    screenshot = cv2.cvtColor(screenshot, cv2.COLOR_RGB2BGR)  # Convertir a BGR (OpenCV usa BGR por defecto)\n",
    "\n",
    "    # Realizar la predicción\n",
    "    predicted_class_name, confidence = predict_plant(screenshot)\n",
    "\n",
    "    # Mostrar el resultado en la pantalla\n",
    "    label = f\"{predicted_class_name} ({confidence * 100:.2f}%)\"  # Formato: \"Clase (Confianza %)\"\n",
    "\n",
    "    # Mostrar el texto en la pantalla\n",
    "    cv2.putText(screenshot, f\"-> {label}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, .7, (255, 255, 255), 2)\n",
    "    cv2.putText(screenshot, f\"Confianza: {confidence:.2f}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, .7, (255, 255, 255), 2)\n",
    "\n",
    "    # Mostrar la imagen en una ventana\n",
    "    cv2.imshow(\"Detección en tiempo real\", screenshot)\n",
    "\n",
    "    # Salir del bucle si se presiona la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cerrar la ventana\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
