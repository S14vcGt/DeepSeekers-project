{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpeta = \"../plantvillage_dataset/grayscale/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo para entrenar el modelo a blanco y negro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1. Configurar rutas y parámetros\n",
    "dataset_path = carpeta  # Cambia esto a la ruta de tu dataset\n",
    "target_size = (128, 128)  # Redimensionar a 128x128\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# 2. Preprocesamiento y aumento de datos\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,  # Normalización de píxeles\n",
    "    rotation_range=20,  # Rotación aleatoria\n",
    "    width_shift_range=0.2,  # Desplazamiento horizontal aleatorio\n",
    "    height_shift_range=0.2,  # Desplazamiento vertical aleatorio\n",
    "    horizontal_flip=True,  # Volteo horizontal aleatorio\n",
    "    validation_split=0.2  # 20% de los datos para validación\n",
    ")\n",
    "\n",
    "# 3. Cargar las imágenes de las 3 clases\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=target_size,\n",
    "    color_mode='grayscalegrayscale',  # Cargar en escala de grises\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Clasificación multiclase\n",
    "    classes=['Tomato___healthy', 'Tomato___Late_blight', 'Tomato___Septoria_leaf_spot'],  # Tres clases\n",
    "    subset='training'  # Conjunto de entrenamiento\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=target_size,\n",
    "    color_mode='grayscale',  # Cargar en escala de grises\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Clasificación multiclase\n",
    "    classes=['Tomato___healthy', 'Tomato___Late_blight', 'Tomato___Septoria_leaf_spot'],  # Tres clases\n",
    "    subset='validation'  # Conjunto de validación\n",
    ")\n",
    "\n",
    "# 4. Construir el modelo\n",
    "model = Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')  # Capa de salida para 3 clases\n",
    "])\n",
    "\n",
    "# 5. Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Pérdida para clasificación multiclase\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 6. Resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "# 7. Entrenar el modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# 8. Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Pérdida en validación: {loss}\")\n",
    "print(f\"Precisión en validación: {accuracy}\")\n",
    "\n",
    "# 9. Guardar el modelo\n",
    "model.save(\"modelo_tomate_3_clases.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo para graficar la confianza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'], label='Precisión en entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Precisión en validación')\n",
    "plt.title('Precisión durante el entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de pérdida\n",
    "plt.plot(history.history['loss'], label='Pérdida en entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida en validación')\n",
    "plt.title('Pérdida durante el entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo para ejecutar el modelo en blanco y negro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pyautogui\n",
    "from PIL import Image\n",
    "\n",
    "# 1. Cargar el modelo entrenado\n",
    "model = tf.keras.models.load_model(\"modelo_tomate_3_clases_escala_grises.keras\")  # Asegúrate de que el modelo esté en la ruta correcta\n",
    "\n",
    "# 2. Definir el tamaño de la región de la pantalla a capturar\n",
    "screen_width, screen_height = 400, 400  # Resolución de 400x400\n",
    "\n",
    "# 3. Definir las etiquetas de las clases\n",
    "class_names = ['Bueno', \"Late\", 'Septoria']\n",
    "\n",
    "# 4. Función para preprocesar la imagen\n",
    "def preprocess_image(image):\n",
    "    # Convertir a escala de grises\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Redimensionar a 256x256 (tamaño esperado por el modelo)\n",
    "    resized_image = cv2.resize(gray_image, (128, 128))\n",
    "    # Normalizar los valores de píxeles\n",
    "    normalized_image = resized_image / 255.0\n",
    "    # Expandir dimensiones para que coincida con la entrada del modelo (256, 256, 1)\n",
    "    input_image = np.expand_dims(normalized_image, axis=-1)\n",
    "    input_image = np.expand_dims(input_image, axis=0)  # Añadir dimensión del batch\n",
    "    return input_image\n",
    "\n",
    "# 5. Función para predecir la clase y la confianza\n",
    "def predict_plant(image):\n",
    "    # Preprocesar la imagen\n",
    "    input_image = preprocess_image(image)\n",
    "    # Realizar la predicción\n",
    "    predictions = model.predict(input_image)\n",
    "    # Obtener la clase predicha y su confianza\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]  # Índice de la clase predicha\n",
    "    predicted_class_name = class_names[predicted_class_index]  # Nombre de la clase predicha\n",
    "    confidence = np.max(predictions)  # Confianza de la predicción (valor máximo del array de predicciones)\n",
    "    return predicted_class_name, confidence\n",
    "\n",
    "# 6. Capturar la pantalla en tiempo real y realizar predicciones\n",
    "print(\"Iniciando detección en tiempo real...\")\n",
    "while True:\n",
    "    # Capturar la pantalla\n",
    "    screenshot = pyautogui.screenshot(region=(200, 300, screen_width, screen_height))\n",
    "    screenshot = np.array(screenshot)  # Convertir a un array de NumPy\n",
    "    screenshot = cv2.cvtColor(screenshot, cv2.COLOR_RGB2BGR)  # Convertir a BGR (OpenCV usa BGR por defecto)\n",
    "\n",
    "    # Realizar la predicción\n",
    "    predicted_class_name, confidence = predict_plant(screenshot)\n",
    "\n",
    "    # Mostrar el resultado en la pantalla\n",
    "    label = f\"{predicted_class_name} ({confidence * 100:.2f}%)\"  # Formato: \"Clase (Confianza %)\"\n",
    "\n",
    "    # Mostrar el texto en la pantalla\n",
    "    cv2.putText(screenshot, f\"Estado: {label}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(screenshot, f\"Confianza: {confidence:.2f}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Mostrar la imagen en una ventana\n",
    "    cv2.imshow(\"Detección en tiempo real\", screenshot)\n",
    "\n",
    "    # Salir del bucle si se presiona la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cerrar la ventana\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo para ejecutar modelos a color con trakeo de hojas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pyautogui\n",
    "from PIL import Image\n",
    "\n",
    "# 1. Cargar el modelo entrenado\n",
    "model = tf.keras.models.load_model(\"modelo_tomate_3_color2.keras\")  # Asegúrate de que el modelo esté en la ruta correcta\n",
    "\n",
    "# 2. Definir el tamaño de la región de la pantalla a capturar\n",
    "screen_width, screen_height = 400, 400  # Resolución de 400x400\n",
    "\n",
    "# 3. Definir las etiquetas de las clases\n",
    "class_names = ['Bueno', \"Late\", 'Septoria']\n",
    "\n",
    "# 4. Función para preprocesar la imagen (ahora en color)\n",
    "def preprocess_image(image):\n",
    "    # Redimensionar a 128x128 (tamaño esperado por el modelo)\n",
    "    resized_image = cv2.resize(image, (128, 128))\n",
    "    # Normalizar los valores de píxeles\n",
    "    normalized_image = resized_image / 255.0\n",
    "    # Expandir dimensiones para que coincida con la entrada del modelo (128, 128, 3)\n",
    "    input_image = np.expand_dims(normalized_image, axis=0)  # Añadir dimensión del batch\n",
    "    return input_image\n",
    "\n",
    "# 5. Función para detectar la hoja en la imagen\n",
    "def detect_leaf(image):\n",
    "    # Convertir la imagen a espacio de color HSV\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Definir un rango de color verde para detectar la hoja\n",
    "    lower_green = np.array([35, 50, 50])  # Límite inferior del verde\n",
    "    upper_green = np.array([85, 255, 255])  # Límite superior del verde\n",
    "    \n",
    "    # Crear una máscara para el color verde\n",
    "    mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "    \n",
    "    # Encontrar contornos en la máscara\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Si se detectan contornos, encontrar el más grande (la hoja)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        # Obtener las coordenadas del rectángulo que encierra la hoja\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        return (x, y, w, h)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# 6. Función para predecir la clase y la confianza\n",
    "def predict_plant(image):\n",
    "    # Preprocesar la imagen\n",
    "    input_image = preprocess_image(image)\n",
    "    # Realizar la predicción\n",
    "    predictions = model.predict(input_image)\n",
    "    # Obtener la clase predicha y su confianza\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]  # Índice de la clase predicha\n",
    "    predicted_class_name = class_names[predicted_class_index]  # Nombre de la clase predicha\n",
    "    confidence = np.max(predictions)  # Confianza de la predicción (valor máximo del array de predicciones)\n",
    "    return predicted_class_name, confidence\n",
    "\n",
    "# 7. Capturar la pantalla en tiempo real y realizar predicciones\n",
    "print(\"Iniciando detección en tiempo real...\")\n",
    "while True:\n",
    "    # Capturar la pantalla\n",
    "    screenshot = pyautogui.screenshot(region=(200, 300, screen_width, screen_height))\n",
    "    screenshot = np.array(screenshot)  # Convertir a un array de NumPy\n",
    "    screenshot = cv2.cvtColor(screenshot, cv2.COLOR_RGB2BGR)  # Convertir a BGR (OpenCV usa BGR por defecto)\n",
    "\n",
    "    # Detectar la hoja en la imagen\n",
    "    leaf_box = detect_leaf(screenshot)\n",
    "    \n",
    "    # Si se detecta la hoja, dibujar un rectángulo naranja alrededor\n",
    "    if leaf_box:\n",
    "        x, y, w, h = leaf_box\n",
    "        cv2.rectangle(screenshot, (x, y), (x + w, y + h), (0, 165, 255), 2)  # Rectángulo naranja\n",
    "\n",
    "    # Realizar la predicción\n",
    "    predicted_class_name, confidence = predict_plant(screenshot)\n",
    "\n",
    "    # Mostrar el resultado en la pantalla\n",
    "    label = f\"{predicted_class_name} ({confidence * 100:.2f}%)\"  # Formato: \"Clase (Confianza %)\"\n",
    "\n",
    "    # Mostrar el texto en la pantalla\n",
    "    cv2.putText(screenshot, f\"Estado: {label}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.putText(screenshot, f\"Confianza: {confidence:.2f}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Mostrar la imagen en una ventana\n",
    "    cv2.imshow(\"Detección en tiempo real\", screenshot)\n",
    "\n",
    "    # Salir del bucle si se presiona la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cerrar la ventana\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
